{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZHDV9TwsDaG/YSa5Fic+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harooniqbal4879/AgenticAI/blob/main/Lead_Gen_%26_Outreach_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've created a comprehensive Colab notebook for healthcare lead generation focused on finding nursing homes, hospitals, and other healthcare facilities that need shift nurses. Here are the key features:\n",
        "\n",
        "# üè• Core Capabilities:\n",
        "\n",
        "Multi-Source Lead Generation:\n",
        "\n",
        "Google search integration for healthcare facilities\n",
        "Web scraping for facility information\n",
        "LinkedIn and social media link extraction\n",
        "Contact information discovery\n",
        "\n",
        "\n",
        "Healthcare Facility Types Covered:\n",
        "\n",
        "Nursing Homes\n",
        "Hospitals & Medical Centers\n",
        "Assisted Living Facilities\n",
        "Senior Care Centers\n",
        "Home Health Agencies\n",
        "Medical Clinics\n",
        "\n",
        "\n",
        "Data Extraction Features:\n",
        "\n",
        "Facility name and type identification\n",
        "Contact information (phone, email)\n",
        "Address and location data\n",
        "Career page detection\n",
        "Nursing job indicators\n",
        "Social media presence\n",
        "Lead scoring and qualification\n",
        "\n",
        "\n",
        "# New Section\n",
        "# üéØ Lead Qualification System:\n",
        "# The system automatically scores leads based on:\n",
        "\n",
        "Available contact information (+2-4 points)\n",
        "Active careers page (+3 points)\n",
        "Nursing hiring indicators (+4 points)\n",
        "Social media presence (+1 point)\n",
        "Job-related keywords (+2 points)\n",
        "\n",
        "# üìä Output & Export:\n",
        "\n",
        "Excel export with multiple sheets\n",
        "Qualified leads filtering\n",
        "Summary statistics\n",
        "Lead scoring and notes\n",
        "\n",
        "üìß Outreach Templates:\n",
        "# Includes pre-written email templates for:\n",
        "\n",
        "Initial contact\n",
        "Follow-up emails\n",
        "Career page outreach\n",
        "\n",
        "üöÄ How to Use:\n",
        "\n",
        "Run the notebook in Google Colab\n",
        "Execute: df, qualified_df = run_lead_generation('Your City, State', max_facilities=20)\n",
        "View results: display_results(df)\n",
        "Export: export_results(df, 'healthcare_leads.xlsx')\n",
        "\n",
        "The system is designed to be respectful of websites with built-in delays and follows ethical scraping practices. It focuses specifically on healthcare facilities that are likely to need nursing staff, making it highly targeted for your use case.\n",
        "Would you like me to add any specific features or modify the search criteria for particular types of healthcare facilities?RetryClaude can make mistakes. Please double-check responses."
      ],
      "metadata": {
        "id": "NZfQmRyAc2DK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScaIMiK2c0Yc",
        "outputId": "87804ec5-2440-416d-ab38-3af5e3dd9d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.34.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.34.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
            "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, python-dotenv, outcome, webdriver-manager, trio, googlesearch-python, trio-websocket, selenium\n",
            "Successfully installed googlesearch-python-1.3.0 outcome-1.3.0.post0 python-dotenv-1.1.1 selenium-4.34.0 trio-0.30.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.2.0\n",
            "Healthcare Lead Generation & Outreach Agent\n",
            "==================================================\n",
            "Healthcare Lead Generation System Ready!\n",
            "\n",
            "To run lead generation, use:\n",
            "df, qualified_df = run_lead_generation('Your City, State', max_facilities=20)\n",
            "\n",
            "To display results, use:\n",
            "display_results(df)\n",
            "\n",
            "To export results, use:\n",
            "export_results(df, 'your_filename.xlsx')\n",
            "\n",
            "Outreach templates are available in the 'templates' variable\n",
            "Template types: ['initial_contact', 'follow_up', 'careers_page_contact']\n"
          ]
        }
      ],
      "source": [
        "# Healthcare Lead Generation & Outreach Agent\n",
        "# Focused on Nursing Homes, Hospitals, and Healthcare Facilities\n",
        "\n",
        "# Install required packages\n",
        "!pip install requests beautifulsoup4 pandas selenium webdriver-manager lxml openpyxl googlesearch-python\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data storage\n",
        "leads_data = []\n",
        "processed_urls = set()\n",
        "\n",
        "class HealthcareLeadGenerator:\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        })\n",
        "        self.leads = []\n",
        "\n",
        "    def search_google_for_facilities(self, location=\"\", facility_type=\"nursing home\"):\n",
        "        \"\"\"Search Google for healthcare facilities\"\"\"\n",
        "        try:\n",
        "            from googlesearch import search\n",
        "\n",
        "            queries = [\n",
        "                f\"{facility_type} {location} hiring nurses\",\n",
        "                f\"{facility_type} {location} job openings\",\n",
        "                f\"{facility_type} {location} careers\",\n",
        "                f\"{facility_type} {location} contact\"\n",
        "            ]\n",
        "\n",
        "            urls = []\n",
        "            for query in queries:\n",
        "                try:\n",
        "                    search_results = search(query, num_results=10, sleep_interval=2)\n",
        "                    urls.extend(list(search_results))\n",
        "                    time.sleep(1)\n",
        "                except Exception as e:\n",
        "                    print(f\"Search error for '{query}': {e}\")\n",
        "                    continue\n",
        "\n",
        "            return list(set(urls))  # Remove duplicates\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"Google search not available. Using manual URL collection.\")\n",
        "            return []\n",
        "\n",
        "    def extract_facility_info(self, url):\n",
        "        \"\"\"Extract facility information from a website\"\"\"\n",
        "        try:\n",
        "            response = self.session.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Extract basic information\n",
        "            title = soup.find('title').text.strip() if soup.find('title') else \"\"\n",
        "\n",
        "            # Look for contact information\n",
        "            contact_info = self.extract_contact_info(soup)\n",
        "\n",
        "            # Look for job/career indicators\n",
        "            job_indicators = self.find_job_indicators(soup, response.text)\n",
        "\n",
        "            # Extract address information\n",
        "            address_info = self.extract_address_info(soup)\n",
        "\n",
        "            facility_data = {\n",
        "                'name': self.extract_facility_name(soup, title),\n",
        "                'url': url,\n",
        "                'title': title,\n",
        "                'phone': contact_info.get('phone', ''),\n",
        "                'email': contact_info.get('email', ''),\n",
        "                'address': address_info.get('address', ''),\n",
        "                'city': address_info.get('city', ''),\n",
        "                'state': address_info.get('state', ''),\n",
        "                'zip_code': address_info.get('zip', ''),\n",
        "                'facility_type': self.determine_facility_type(title, response.text),\n",
        "                'has_careers_page': job_indicators.get('has_careers', False),\n",
        "                'hiring_nurses': job_indicators.get('hiring_nurses', False),\n",
        "                'job_keywords_found': job_indicators.get('keywords', []),\n",
        "                'social_media': self.extract_social_media(soup),\n",
        "                'description': self.extract_description(soup)\n",
        "            }\n",
        "\n",
        "            return facility_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {url}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_contact_info(self, soup):\n",
        "        \"\"\"Extract phone and email from webpage\"\"\"\n",
        "        text = soup.get_text()\n",
        "\n",
        "        # Phone number patterns\n",
        "        phone_patterns = [\n",
        "            r'\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b',\n",
        "            r'\\(\\d{3}\\)\\s*\\d{3}[-.\\s]?\\d{4}',\n",
        "            r'\\b\\d{10}\\b'\n",
        "        ]\n",
        "\n",
        "        phones = []\n",
        "        for pattern in phone_patterns:\n",
        "            phones.extend(re.findall(pattern, text))\n",
        "\n",
        "        # Email pattern\n",
        "        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "        emails = re.findall(email_pattern, text)\n",
        "\n",
        "        return {\n",
        "            'phone': phones[0] if phones else '',\n",
        "            'email': emails[0] if emails else ''\n",
        "        }\n",
        "\n",
        "    def extract_address_info(self, soup):\n",
        "        \"\"\"Extract address information\"\"\"\n",
        "        text = soup.get_text()\n",
        "\n",
        "        # Look for address patterns\n",
        "        address_elements = soup.find_all(['address', 'div', 'p'],\n",
        "                                       class_=re.compile(r'address|location|contact', re.I))\n",
        "\n",
        "        address_text = \"\"\n",
        "        for elem in address_elements:\n",
        "            address_text += elem.get_text() + \" \"\n",
        "\n",
        "        if not address_text:\n",
        "            address_text = text\n",
        "\n",
        "        # Extract state abbreviations\n",
        "        state_pattern = r'\\b[A-Z]{2}\\b'\n",
        "        states = re.findall(state_pattern, address_text)\n",
        "\n",
        "        # Extract ZIP codes\n",
        "        zip_pattern = r'\\b\\d{5}(?:-\\d{4})?\\b'\n",
        "        zips = re.findall(zip_pattern, address_text)\n",
        "\n",
        "        return {\n",
        "            'address': address_text[:200],  # Truncate for brevity\n",
        "            'state': states[0] if states else '',\n",
        "            'zip': zips[0] if zips else '',\n",
        "            'city': ''  # Would need more complex extraction\n",
        "        }\n",
        "\n",
        "    def find_job_indicators(self, soup, text):\n",
        "        \"\"\"Look for job and career indicators\"\"\"\n",
        "        job_keywords = [\n",
        "            'hiring', 'jobs', 'careers', 'employment', 'positions',\n",
        "            'rn', 'nurse', 'nursing', 'lpn', 'cna', 'staff', 'shift'\n",
        "        ]\n",
        "\n",
        "        nursing_keywords = [\n",
        "            'registered nurse', 'rn', 'lpn', 'cna', 'nursing assistant',\n",
        "            'shift nurse', 'staff nurse', 'charge nurse'\n",
        "        ]\n",
        "\n",
        "        text_lower = text.lower()\n",
        "        found_keywords = [kw for kw in job_keywords if kw in text_lower]\n",
        "        nursing_found = any(kw in text_lower for kw in nursing_keywords)\n",
        "\n",
        "        # Look for career/job links\n",
        "        career_links = soup.find_all('a', href=re.compile(r'career|job|employment', re.I))\n",
        "        has_careers = len(career_links) > 0\n",
        "\n",
        "        return {\n",
        "            'has_careers': has_careers,\n",
        "            'hiring_nurses': nursing_found,\n",
        "            'keywords': found_keywords\n",
        "        }\n",
        "\n",
        "    def extract_facility_name(self, soup, title):\n",
        "        \"\"\"Extract facility name from various sources\"\"\"\n",
        "        # Try h1 tag first\n",
        "        h1 = soup.find('h1')\n",
        "        if h1:\n",
        "            return h1.get_text().strip()\n",
        "\n",
        "        # Try title tag\n",
        "        if title:\n",
        "            # Clean up title\n",
        "            name = re.sub(r'\\s*[-|]\\s*.*$', '', title)\n",
        "            return name.strip()\n",
        "\n",
        "        # Try meta property\n",
        "        og_title = soup.find('meta', property='og:title')\n",
        "        if og_title:\n",
        "            return og_title.get('content', '').strip()\n",
        "\n",
        "        return \"Unknown Facility\"\n",
        "\n",
        "    def determine_facility_type(self, title, text):\n",
        "        \"\"\"Determine the type of healthcare facility\"\"\"\n",
        "        text_lower = (title + \" \" + text).lower()\n",
        "\n",
        "        if any(term in text_lower for term in ['nursing home', 'skilled nursing', 'long term care']):\n",
        "            return 'Nursing Home'\n",
        "        elif any(term in text_lower for term in ['hospital', 'medical center', 'health system']):\n",
        "            return 'Hospital'\n",
        "        elif any(term in text_lower for term in ['assisted living', 'senior living', 'retirement']):\n",
        "            return 'Assisted Living'\n",
        "        elif any(term in text_lower for term in ['clinic', 'medical clinic']):\n",
        "            return 'Clinic'\n",
        "        elif any(term in text_lower for term in ['home health', 'home care']):\n",
        "            return 'Home Health'\n",
        "        else:\n",
        "            return 'Healthcare Facility'\n",
        "\n",
        "    def extract_social_media(self, soup):\n",
        "        \"\"\"Extract social media links\"\"\"\n",
        "        social_links = {}\n",
        "        social_patterns = {\n",
        "            'facebook': r'facebook\\.com',\n",
        "            'linkedin': r'linkedin\\.com',\n",
        "            'twitter': r'twitter\\.com',\n",
        "            'instagram': r'instagram\\.com'\n",
        "        }\n",
        "\n",
        "        links = soup.find_all('a', href=True)\n",
        "        for link in links:\n",
        "            href = link['href']\n",
        "            for platform, pattern in social_patterns.items():\n",
        "                if re.search(pattern, href, re.I):\n",
        "                    social_links[platform] = href\n",
        "                    break\n",
        "\n",
        "        return social_links\n",
        "\n",
        "    def extract_description(self, soup):\n",
        "        \"\"\"Extract facility description\"\"\"\n",
        "        # Try meta description first\n",
        "        meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
        "        if meta_desc:\n",
        "            return meta_desc.get('content', '').strip()\n",
        "\n",
        "        # Try first paragraph\n",
        "        paragraphs = soup.find_all('p')\n",
        "        if paragraphs:\n",
        "            return paragraphs[0].get_text().strip()[:200]\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "# Initialize the lead generator\n",
        "lead_gen = HealthcareLeadGenerator()\n",
        "\n",
        "# Sample healthcare facility URLs for testing\n",
        "sample_urls = [\n",
        "    \"https://www.sunriseseniorliving.com/\",\n",
        "    \"https://www.brookdale.com/\",\n",
        "    \"https://www.gentiva.com/\",\n",
        "    \"https://www.goldenliving.com/\",\n",
        "    \"https://www.amedisys.com/\"\n",
        "]\n",
        "\n",
        "print(\"Healthcare Lead Generation & Outreach Agent\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Function to search for facilities by location and type\n",
        "def search_facilities(location=\"New York\", facility_types=None):\n",
        "    \"\"\"Search for healthcare facilities in a specific location\"\"\"\n",
        "    if facility_types is None:\n",
        "        facility_types = [\"nursing home\", \"hospital\", \"assisted living\", \"senior care\"]\n",
        "\n",
        "    all_urls = []\n",
        "\n",
        "    for facility_type in facility_types:\n",
        "        print(f\"\\nSearching for {facility_type} facilities in {location}...\")\n",
        "        urls = lead_gen.search_google_for_facilities(location, facility_type)\n",
        "        all_urls.extend(urls)\n",
        "        print(f\"Found {len(urls)} potential leads for {facility_type}\")\n",
        "\n",
        "    return list(set(all_urls))  # Remove duplicates\n",
        "\n",
        "# Function to process URLs and extract facility data\n",
        "def process_facilities(urls, max_facilities=20):\n",
        "    \"\"\"Process a list of URLs to extract facility information\"\"\"\n",
        "    facilities = []\n",
        "\n",
        "    print(f\"\\nProcessing up to {max_facilities} facilities...\")\n",
        "\n",
        "    for i, url in enumerate(urls[:max_facilities]):\n",
        "        if url in processed_urls:\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {i+1}/{min(len(urls), max_facilities)}: {url}\")\n",
        "\n",
        "        facility_data = lead_gen.extract_facility_info(url)\n",
        "        if facility_data:\n",
        "            facilities.append(facility_data)\n",
        "            processed_urls.add(url)\n",
        "\n",
        "        # Add delay to be respectful to websites\n",
        "        time.sleep(1)\n",
        "\n",
        "    return facilities\n",
        "\n",
        "# Function to qualify leads\n",
        "def qualify_leads(facilities):\n",
        "    \"\"\"Qualify leads based on various criteria\"\"\"\n",
        "    qualified_leads = []\n",
        "\n",
        "    for facility in facilities:\n",
        "        score = 0\n",
        "        qualification_notes = []\n",
        "\n",
        "        # Scoring criteria\n",
        "        if facility['phone']:\n",
        "            score += 2\n",
        "            qualification_notes.append(\"Has phone number\")\n",
        "\n",
        "        if facility['email']:\n",
        "            score += 2\n",
        "            qualification_notes.append(\"Has email\")\n",
        "\n",
        "        if facility['has_careers_page']:\n",
        "            score += 3\n",
        "            qualification_notes.append(\"Has careers page\")\n",
        "\n",
        "        if facility['hiring_nurses']:\n",
        "            score += 4\n",
        "            qualification_notes.append(\"Actively hiring nurses\")\n",
        "\n",
        "        if facility['social_media']:\n",
        "            score += 1\n",
        "            qualification_notes.append(\"Has social media presence\")\n",
        "\n",
        "        if len(facility['job_keywords_found']) > 2:\n",
        "            score += 2\n",
        "            qualification_notes.append(\"Multiple job-related keywords found\")\n",
        "\n",
        "        facility['lead_score'] = score\n",
        "        facility['qualification_notes'] = qualification_notes\n",
        "        facility['qualified'] = score >= 4\n",
        "\n",
        "        if facility['qualified']:\n",
        "            qualified_leads.append(facility)\n",
        "\n",
        "    return qualified_leads\n",
        "\n",
        "# Function to create outreach templates\n",
        "def create_outreach_templates():\n",
        "    \"\"\"Create email templates for outreach\"\"\"\n",
        "    templates = {\n",
        "        'initial_contact': \"\"\"\n",
        "Subject: Staffing Solutions for {facility_name} - Qualified Nurses Available\n",
        "\n",
        "Dear Hiring Manager,\n",
        "\n",
        "I hope this email finds you well. I'm reaching out regarding potential staffing needs at {facility_name}.\n",
        "\n",
        "We specialize in providing qualified nursing professionals for healthcare facilities, including:\n",
        "- Registered Nurses (RN)\n",
        "- Licensed Practical Nurses (LPN)\n",
        "- Certified Nursing Assistants (CNA)\n",
        "- Shift and temporary staffing solutions\n",
        "\n",
        "Our nurses are thoroughly vetted, licensed, and ready to support your facility's needs. We understand the challenges of maintaining adequate staffing levels while ensuring quality patient care.\n",
        "\n",
        "Would you be interested in learning more about our staffing solutions? I'd be happy to discuss how we can support {facility_name}.\n",
        "\n",
        "Best regards,\n",
        "[Your Name]\n",
        "[Your Contact Information]\n",
        "        \"\"\",\n",
        "\n",
        "        'follow_up': \"\"\"\n",
        "Subject: Follow-up: Nursing Staffing Solutions for {facility_name}\n",
        "\n",
        "Dear Hiring Manager,\n",
        "\n",
        "I wanted to follow up on my previous email regarding nursing staffing solutions for {facility_name}.\n",
        "\n",
        "Given the current healthcare staffing challenges, many facilities are finding value in having reliable backup staffing options. Our services include:\n",
        "- Emergency shift coverage\n",
        "- Seasonal staffing support\n",
        "- Specialized nursing skills\n",
        "- Flexible scheduling options\n",
        "\n",
        "Would you have 10 minutes this week for a brief conversation about your current staffing needs?\n",
        "\n",
        "Best regards,\n",
        "[Your Name]\n",
        "        \"\"\",\n",
        "\n",
        "        'careers_page_contact': \"\"\"\n",
        "Subject: Nursing Staffing Partnership Opportunity - {facility_name}\n",
        "\n",
        "Dear Hiring Team,\n",
        "\n",
        "I noticed that {facility_name} has an active careers page, which suggests you may have ongoing staffing needs.\n",
        "\n",
        "We partner with healthcare facilities to provide qualified nursing staff when needed. This can help you:\n",
        "- Reduce overtime costs\n",
        "- Maintain quality patient care during staff shortages\n",
        "- Access specialized nursing skills\n",
        "- Provide flexibility during peak periods\n",
        "\n",
        "Would you be open to exploring a partnership discussion?\n",
        "\n",
        "Best regards,\n",
        "[Your Name]\n",
        "        \"\"\"\n",
        "    }\n",
        "\n",
        "    return templates\n",
        "\n",
        "# Main execution functions\n",
        "def run_lead_generation(location=\"New York\", max_facilities=10):\n",
        "    \"\"\"Run the complete lead generation process\"\"\"\n",
        "    print(\"Starting Healthcare Lead Generation Process...\")\n",
        "\n",
        "    # Step 1: Search for facilities\n",
        "    facility_urls = search_facilities(location)\n",
        "    print(f\"\\nTotal unique URLs found: {len(facility_urls)}\")\n",
        "\n",
        "    # Step 2: Process facilities\n",
        "    facilities = process_facilities(facility_urls, max_facilities)\n",
        "    print(f\"\\nSuccessfully processed {len(facilities)} facilities\")\n",
        "\n",
        "    # Step 3: Qualify leads\n",
        "    qualified_leads = qualify_leads(facilities)\n",
        "    print(f\"\\nQualified {len(qualified_leads)} leads out of {len(facilities)} total\")\n",
        "\n",
        "    # Step 4: Create DataFrame for analysis\n",
        "    df = pd.DataFrame(facilities)\n",
        "    qualified_df = pd.DataFrame(qualified_leads)\n",
        "\n",
        "    return df, qualified_df\n",
        "\n",
        "# Function to export results\n",
        "def export_results(df, filename=\"healthcare_leads.xlsx\"):\n",
        "    \"\"\"Export results to Excel file\"\"\"\n",
        "    try:\n",
        "        # Create Excel writer object\n",
        "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "            # All leads\n",
        "            df.to_excel(writer, sheet_name='All_Leads', index=False)\n",
        "\n",
        "            # Qualified leads only\n",
        "            qualified_df = df[df['qualified'] == True]\n",
        "            qualified_df.to_excel(writer, sheet_name='Qualified_Leads', index=False)\n",
        "\n",
        "            # Summary statistics\n",
        "            summary_data = {\n",
        "                'Metric': ['Total Facilities', 'Qualified Leads', 'With Phone', 'With Email', 'With Careers Page'],\n",
        "                'Count': [\n",
        "                    len(df),\n",
        "                    len(qualified_df),\n",
        "                    len(df[df['phone'] != '']),\n",
        "                    len(df[df['email'] != '']),\n",
        "                    len(df[df['has_careers_page'] == True])\n",
        "                ]\n",
        "            }\n",
        "            summary_df = pd.DataFrame(summary_data)\n",
        "            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "        print(f\"Results exported to {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting results: {e}\")\n",
        "\n",
        "# Function to display results\n",
        "def display_results(df):\n",
        "    \"\"\"Display results in a formatted way\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"HEALTHCARE LEAD GENERATION RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\nTotal Facilities Processed: {len(df)}\")\n",
        "    print(f\"Qualified Leads: {len(df[df['qualified'] == True])}\")\n",
        "    print(f\"Facilities with Phone: {len(df[df['phone'] != ''])}\")\n",
        "    print(f\"Facilities with Email: {len(df[df['email'] != ''])}\")\n",
        "    print(f\"Facilities with Careers Page: {len(df[df['has_careers_page'] == True])}\")\n",
        "\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(\"TOP QUALIFIED LEADS:\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    qualified_leads = df[df['qualified'] == True].sort_values('lead_score', ascending=False)\n",
        "\n",
        "    for idx, lead in qualified_leads.head(10).iterrows():\n",
        "        print(f\"\\n{lead['name']}\")\n",
        "        print(f\"Type: {lead['facility_type']}\")\n",
        "        print(f\"URL: {lead['url']}\")\n",
        "        print(f\"Phone: {lead['phone']}\")\n",
        "        print(f\"Email: {lead['email']}\")\n",
        "        print(f\"Lead Score: {lead['lead_score']}\")\n",
        "        print(f\"Notes: {', '.join(lead['qualification_notes'])}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "# Example usage\n",
        "print(\"Healthcare Lead Generation System Ready!\")\n",
        "print(\"\\nTo run lead generation, use:\")\n",
        "print(\"df, qualified_df = run_lead_generation('Your City, State', max_facilities=20)\")\n",
        "print(\"\\nTo display results, use:\")\n",
        "print(\"display_results(df)\")\n",
        "print(\"\\nTo export results, use:\")\n",
        "print(\"export_results(df, 'your_filename.xlsx')\")\n",
        "\n",
        "# Get outreach templates\n",
        "templates = create_outreach_templates()\n",
        "print(\"\\nOutreach templates are available in the 'templates' variable\")\n",
        "print(\"Template types:\", list(templates.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XgRn_Xqac1qI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}