{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "My First Agentic AI Proejct"
      ],
      "metadata": {
        "id": "yEmZC4ZgBEZN"
      },
      "id": "yEmZC4ZgBEZN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -U langchain-community openai faiss-cpu tiktoken pypdf streamlit --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfxT9ziOBC9a",
        "outputId": "9af172e3-e8b6-4774-c341-e2e2dddec386"
      },
      "id": "RfxT9ziOBC9a",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.3/734.3 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Set your OpenAI API Key\n",
        "os.environ['OPENAI_API_KEY'] = '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'  # Replace with your key\n"
      ],
      "metadata": {
        "id": "_kCApZC3BC8T"
      },
      "id": "_kCApZC3BC8T",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load PDF\n",
        "pdf_path = \"/var/SW_Company.pdf\"  # Upload your file manually to Colab\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "C9rf9LShBC3W"
      },
      "id": "C9rf9LShBC3W",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split text into chunks\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "pKMcPQiQBC2X"
      },
      "id": "pKMcPQiQBC2X",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Embed and store in FAISS\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIAjkjfUBC1N",
        "outputId": "f0a83dbc-7392-417a-b6a7-5f4d3697310b"
      },
      "id": "vIAjkjfUBC1N",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-3637925752.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Set up LangChain QA chain\n",
        "llm = OpenAI(temperature=0.2)\n",
        "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSK0vouPBCw9",
        "outputId": "86480596-4250-4d50-c220-59dfd13e4693"
      },
      "id": "sSK0vouPBCw9",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-8718721.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(temperature=0.2)\n",
            "/tmp/ipython-input-10-8718721.py:3: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
            "  qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Ask a question\n",
        "query = \"What is the main topic of the document?\"\n",
        "relevant_docs = vectorstore.similarity_search(query)\n",
        "response = qa_chain.run(input_documents=relevant_docs, question=query)\n",
        "\n",
        "print(\"Q:\", query)\n",
        "print(\"A:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUtBw2sSBCvz",
        "outputId": "6f4dcbbd-3688-49be-bdea-3d87bec03646"
      },
      "id": "GUtBw2sSBCvz",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-4163400530.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = qa_chain.run(input_documents=relevant_docs, question=query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the main topic of the document?\n",
            "A:  The main topic of the document is SW Healthcare Solutions and its value propositions, market leadership through innovation, and a case study on its impact in the healthcare industry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2a1EaVrHBCuf"
      },
      "id": "2a1EaVrHBCuf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58E8Q3ldBCrl"
      },
      "id": "58E8Q3ldBCrl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPpDvmcMBCn3"
      },
      "id": "zPpDvmcMBCn3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymS7opaABClY"
      },
      "id": "ymS7opaABClY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVVP5LcJBCjg"
      },
      "id": "aVVP5LcJBCjg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHVDUmBRBCge"
      },
      "id": "SHVDUmBRBCge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "845fa645",
      "metadata": {
        "id": "845fa645"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "049d05e7",
      "metadata": {
        "id": "049d05e7"
      },
      "outputs": [],
      "source": [
        "# API key here\n",
        "openai_api_key = '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'\n",
        "\n",
        "# don't share this key in public / github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "208bfc64",
      "metadata": {
        "id": "208bfc64"
      },
      "outputs": [],
      "source": [
        "# chat completion method\n",
        "# https://platform.openai.com/docs/guides/text-generation/chat-completions-api\n",
        "client = openai.OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=openai_api_key\n",
        ")\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo-0125\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "576eb1a7",
      "metadata": {
        "id": "576eb1a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113c71bc-8078-4f8e-c98a-5e09cc636b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I am unable to provide real-time weather updates. I recommend checking a reliable weather website or app for the most up-to-date information on the weather conditions in Troy, MI, USA.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "Can you get me the waether condition in Troy, MI, USA?\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n",
        "#If this runs successfully, your API key is working!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee06f91",
      "metadata": {
        "id": "1ee06f91"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f3b2d0",
      "metadata": {
        "id": "13f3b2d0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}